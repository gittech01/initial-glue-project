# Onde S√£o Salvas as Informa√ß√µes das Tabelas?

## üìä RESUMO EXECUTIVO

A aplica√ß√£o salva informa√ß√µes em **3 locais diferentes**, cada um com um prop√≥sito espec√≠fico:

1. **Dados Consolidados (Resultado Final)** ‚Üí **S3 + Glue Data Catalog**
2. **Congregados (Metadados de Processamento)** ‚Üí **DynamoDB**
3. **Controle de Jornada (Estados de Execu√ß√£o)** ‚Üí **DynamoDB**

---

## 1. DADOS CONSOLIDADOS (Resultado Final)

### üìç Local: S3 + Glue Data Catalog

**Onde:**
- **S3**: Localiza√ß√£o da tabela no cat√°logo Glue (obtida automaticamente)
- **Glue Catalog**: Tabela consolidada no banco de dados especificado

**Implementa√ß√£o:**
- **Arquivo**: `app/utils/business/flexible_consolidation_processor.py` (linhas 611-664)
- **M√©todo**: `_write_output()`

**Condi√ß√µes de Salvamento:**

> **IMPORTANTE**: O m√©todo `_should_write_output()` verifica se h√° `tabela_consolidada` + `database` OU `output_path`. Se qualquer um estiver presente, o output ser√° escrito.

#### Caso 1: Com `tabela_consolidada` + `database` (Recomendado)
```python
if tabela_consolidada and database:
    # Salva no S3 (localiza√ß√£o da tabela no cat√°logo)
    # Atualiza o cat√°logo Glue com nova parti√ß√£o
    self.glue_handler.write_to_catalog(
        df=df_consolidado,
        database=database,
        table_name=tabela_consolidada,
        compression='snappy'
    )
```

**Onde √© salvo:**
- **S3**: Caminho obtido do cat√°logo Glue (`table_location` da tabela)
- **Glue Catalog**: `{database}.{tabela_consolidada}`
- **Formato**: Parquet com compress√£o Snappy
- **Parti√ß√£o**: Baseada nas colunas de parti√ß√£o da tabela (geralmente `anomesdia`)

**Exemplo:**
- **Database**: `db_batch`
- **Tabela**: `tbl_processado_operacao_consolidada_n1`
- **S3**: `s3://bucket/db_batch/tbl_processado_operacao_consolidada_n1/anomesdia=20240119/`
- **Glue Catalog**: `db_batch.tbl_processado_operacao_consolidada_n1`

#### Caso 2: Apenas com `output_path`
```python
elif output_path:
    # Salva apenas no S3 (sem atualizar cat√°logo)
    self.glue_handler.write_to_s3(
        df=df_consolidado,
        path=output_path,
        format='parquet',
        compression='snappy'
    )
```

**Onde √© salvo:**
- **S3**: Caminho especificado em `output_path`
- **Glue Catalog**: ‚ùå N√£o atualiza o cat√°logo
- **Formato**: Parquet com compress√£o Snappy

**Exemplo:**
- **Output Path**: `s3://bucket/output/consolidacao/20240119/`
- **Glue Catalog**: ‚ùå N√£o atualizado

---

## 2. CONGREGADOS (Metadados de Processamento)

### üìç Local: DynamoDB

**Tabela DynamoDB:**
- **Nome**: `congregado_data` (configur√°vel via `config.congregado_table_name`)
- **Regi√£o**: `sa-east-1` (configur√°vel via `config.aws_region`)

**Implementa√ß√£o:**
- **Arquivo**: `app/utils/business/base_processor.py` (linhas 155-175)
- **M√©todo**: `_save_congregado()`
- **Handler**: `app/utils/dynamodb_handler.py` (linhas 217-290)

**O que √© salvo:**
```python
{
    'id': '{database}_{tabela_consolidada}',  # Chave prim√°ria
    'idempotency_key': 'hash_do_conteudo',     # Chave de idempot√™ncia
    'record_count': 1000,                      # N√∫mero de registros
    'tabela_consolidada': 'tbl_processado_operacao_consolidada_n1',
    'database': 'db_batch',
    'chaves_principais': ['num_oper', 'cod_idef_ver_oper'],
    'campos_decisao': ['dat_vlr_even_oper', 'num_prio_even_oper', 'dat_recm_even_oper'],
    'sample_data': [...],                      # Amostra dos dados (at√© 1000 registros)
    'processor_type': 'FlexibleConsolidationProcessor',
    'created_at': '2024-01-19T10:00:00',
    'updated_at': '2024-01-19T10:00:00',
    'metadata': {
        'processor_type': 'FlexibleConsolidationProcessor',
        'tabela_consolidada': 'tbl_processado_operacao_consolidada_n1',
        'database': 'db_batch',
        'origens': ['sor', 'sot']
    }
}
```

**Chave Prim√°ria:**
- Formato: `{database}_{tabela_consolidada}`
- Exemplo: `db_batch_tbl_processado_operacao_consolidada_n1`

**Prop√≥sito:**
- Rastreamento de processamentos executados
- Idempot√™ncia (evita reprocessamento)
- Auditoria e hist√≥rico

---

## 3. CONTROLE DE JORNADA (Estados de Execu√ß√£o)

### üìç Local: DynamoDB

**Tabela DynamoDB:**
- **Nome**: `journey_control` (configur√°vel via `config.journey_table_name`)
- **Regi√£o**: `sa-east-1` (configur√°vel via `config.aws_region`)

**Implementa√ß√£o:**
- **Arquivo**: `app/utils/journey_controller.py` (linhas 323-450)
- **M√©todo**: `execute_with_journey()`

**O que √© salvo:**
```python
{
    'idempotency_key': 'hash_do_job_e_parametros',  # Chave de idempot√™ncia
    'status': 'COMPLETED',                           # Status da jornada
    'step': 'completed',                             # Etapa atual
    'started_at': '2024-01-19T10:00:00',
    'completed_at': '2024-01-19T10:05:00',
    'retry_count': 0,
    'metadata': {
        'processor_type': 'FlexibleConsolidationProcessor',
        'database': 'db_batch',
        'tabela_consolidada': 'tbl_processado_operacao_consolidada_n1'
    },
    'result': {...},                                 # Resultado do processamento
    'error': None                                    # Erro (se houver)
}
```

**Chave Prim√°ria:**
- Formato: `idempotency_key` (hash baseado em job + par√¢metros)
- Exemplo: `hash(job_name + database + tabela_consolidada + ...)`

**Prop√≥sito:**
- Controle de execu√ß√£o idempotente
- Retry autom√°tico em caso de falha
- Rastreamento de estados (PENDING, IN_PROGRESS, COMPLETED, FAILED)
- Recupera√ß√£o de processos interrompidos

---

## üìã TABELA RESUMO

| Tipo de Dado | Local | Tabela/Nome | Chave Prim√°ria | Prop√≥sito |
|--------------|-------|-------------|----------------|-----------|
| **Dados Consolidados** | S3 + Glue Catalog | `{database}.{tabela_consolidada}` | Parti√ß√£o (`anomesdia`) | Resultado final da consolida√ß√£o |
| **Congregados** | DynamoDB | `congregado_data` | `{database}_{tabela_consolidada}` | Metadados e amostra dos dados processados |
| **Controle de Jornada** | DynamoDB | `journey_control` | `idempotency_key` (hash) | Estados de execu√ß√£o e idempot√™ncia |

---

## üîç DETALHAMENTO POR TIPO

### 1. Dados Consolidados (S3 + Glue Catalog)

**Fluxo:**
1. Dados s√£o processados e consolidados
2. Se `tabela_consolidada` + `database` fornecidos:
   - Obt√©m localiza√ß√£o S3 da tabela do cat√°logo Glue
   - Salva dados no S3 (formato Parquet, compress√£o Snappy)
   - Atualiza cat√°logo Glue com nova parti√ß√£o
3. Se apenas `output_path` fornecido:
   - Salva dados no S3 no caminho especificado
   - ‚ùå N√£o atualiza cat√°logo Glue

**C√≥digo:**
```python
# app/utils/business/flexible_consolidation_processor.py:639-651
if tabela_consolidada and database:
    self.glue_handler.write_to_catalog(
        df=df_consolidado,
        database=database,
        table_name=tabela_consolidada,
        compression=compression
    )
```

**Localiza√ß√£o S3:**
- Obtida automaticamente do cat√°logo Glue
- Formato: `s3://bucket/{database}/{table_name}/{partition_key}={value}/`
- Exemplo: `s3://bucket/db_batch/tbl_processado_operacao_consolidada_n1/anomesdia=20240119/`

---

### 2. Congregados (DynamoDB)

**Fluxo:**
1. Ap√≥s transforma√ß√£o, dados s√£o salvos como congregado
2. Chave prim√°ria: `{database}_{tabela_consolidada}`
3. Inclui amostra dos dados (at√© 1000 registros)
4. Idempotente: se j√° existe, retorna existente

**C√≥digo:**
```python
# app/utils/business/base_processor.py:155-175
def _save_congregado(self, transformed_data: Dict, **kwargs):
    primary_key = self._get_congregado_key(**kwargs)  # {database}_{tabela_consolidada}
    metadata = self._get_congregado_metadata(**kwargs)
    
    return self.dynamodb_handler.save_congregado(
        congregado_data=transformed_data,
        primary_key=primary_key,
        metadata=metadata
    )
```

**Tabela DynamoDB:**
- **Nome**: `congregado_data` (configur√°vel)
- **Regi√£o**: `sa-east-1` (configur√°vel)
- **Chave Prim√°ria**: `id` (string)

---

### 3. Controle de Jornada (DynamoDB)

**Fluxo:**
1. Antes de executar processamento, cria/atualiza jornada
2. Status inicial: `PENDING` ‚Üí `IN_PROGRESS`
3. Ap√≥s sucesso: `COMPLETED`
4. Em caso de falha: `FAILED` (com retry autom√°tico)

**C√≥digo:**
```python
# app/utils/journey_controller.py:323-450
def execute_with_journey(self, func, idempotency_key, **kwargs):
    # Cria/atualiza jornada no DynamoDB
    # Executa fun√ß√£o
    # Atualiza status
```

**Tabela DynamoDB:**
- **Nome**: `journey_control` (configur√°vel)
- **Regi√£o**: `sa-east-1` (configur√°vel)
- **Chave Prim√°ria**: `idempotency_key` (string, hash)

---

## ‚úÖ VALIDA√á√ÉO

### Configura√ß√µes (settings.py):
- ‚úÖ `journey_table_name = 'journey_control'`
- ‚úÖ `congregado_table_name = 'congregado_data'`
- ‚úÖ `aws_region = 'sa-east-1'`

### Locais de Persist√™ncia Confirmados:

1. **Dados Consolidados**:
   - ‚úÖ S3: Localiza√ß√£o da tabela no cat√°logo Glue
   - ‚úÖ Glue Catalog: `{database}.{tabela_consolidada}`

2. **Congregados**:
   - ‚úÖ DynamoDB: Tabela `congregado_data`
   - ‚úÖ Chave: `{database}_{tabela_consolidada}`

3. **Controle de Jornada**:
   - ‚úÖ DynamoDB: Tabela `journey_control`
   - ‚úÖ Chave: `idempotency_key` (hash)

---

## üìù EXEMPLO PR√ÅTICO

### Execu√ß√£o:
```python
processor.process(
    database='db_batch',
    tabela_consolidada='tbl_processado_operacao_consolidada_n1',
    output_path=None  # Opcional
)
```

### Onde s√£o salvos:

1. **Dados Consolidados**:
   - **S3**: `s3://bucket/db_batch/tbl_processado_operacao_consolidada_n1/anomesdia=20240119/`
   - **Glue Catalog**: `db_batch.tbl_processado_operacao_consolidada_n1`

2. **Congregado**:
   - **DynamoDB**: Tabela `congregado_data`
   - **Chave**: `db_batch_tbl_processado_operacao_consolidada_n1`

3. **Jornada**:
   - **DynamoDB**: Tabela `journey_control`
   - **Chave**: `hash(job_name + db_batch + tbl_processado_operacao_consolidada_n1 + ...)`

---

## üéØ CONCLUS√ÉO

**Todas as informa√ß√µes est√£o sendo salvas nos locais corretos:**

‚úÖ **Dados Consolidados** ‚Üí S3 + Glue Catalog (resultado final)  
‚úÖ **Congregados** ‚Üí DynamoDB (metadados e amostra)  
‚úÖ **Controle de Jornada** ‚Üí DynamoDB (estados de execu√ß√£o)

**Status: ‚úÖ CONFIRMADO - Persist√™ncia correta**
