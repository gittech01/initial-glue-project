Perfeito. Abaixo est√° um **prompt t√©cnico, completo e fiel ao seu contexto**, para voc√™ reutilizar com outro LLM, com um time de desenvolvimento ou como especifica√ß√£o de implementa√ß√£o. Ele est√° estruturado, sem sair da regra de neg√≥cio, com n√≠vel de detalhe suficiente para orientar arquitetura, c√≥digo e valida√ß√µes.

---

## PROMPT ‚Äì CONSOLIDA√á√ÉO SoR x SoT COM PARTI√á√ÉO MAIS RECENTE E REGRAS DIN√ÇMICAS

Voc√™ √© um arquiteto de dados especializado em **AWS Glue, PySpark e arquitetura orientada a regras de neg√≥cio**.

Seu objetivo √© **projetar e implementar uma regra de consolida√ß√£o de dados** que opere sobre m√∫ltiplas tabelas, utilizando uma arquitetura baseada em:

* ProcessorFactory
* BusinessRuleOrchestrator
* JourneyController (controle de idempot√™ncia e jornada)
* GlueDataHandler (I/O com Glue e Data Catalog)
* DynamoDB (controle de execu√ß√£o e m√©tricas)

A solu√ß√£o **n√£o pode usar `spark.sql`** e deve operar apenas com **DataFrames e Glue APIs**.

---

### 1Ô∏è‚É£ Contexto Geral do Neg√≥cio

Existe uma aplica√ß√£o de ingest√£o e consolida√ß√£o que:

* Executa **uma mesma regra de neg√≥cio** para **10 tabelas consolidadas diferentes**.
* Cada tabela consolidada:

  * Possui **1 tabela SoR (online)** e **1 tabela SoT (batch)** com **schema id√™ntico**.
  * Pode possuir **0 a 3 tabelas auxiliares** para SoR e/ou SoT.
* Cada execu√ß√£o:

  * Deve ser **idempotente**.
  * **N√£o pode interromper o processamento das demais tabelas em caso de falha**.
  * Deve registrar a jornada no DynamoDB.
* O processamento √© feito via **AWS Glue Job**.

---

### 2Ô∏è‚É£ Regras de Particionamento (Obrigat√≥rias)

Todas as leituras devem respeitar a seguinte regra:

> **Sempre ler a √öLTIMA PARTI√á√ÉO dispon√≠vel nas tabelas SoR e SoT.**
> Isso deve ser feito:
>
> * Sem usar `spark.sql`.
> * Utilizando Glue APIs (`boto3`/`get_partitions`) ou m√©todos no `GlueDataHandler`.

Se as √∫ltimas parti√ß√µes de SoR e SoT forem **diferentes**, deve-se usar **apenas os dados da parti√ß√£o mais recente** para gerar a consolida√ß√£o.

---

### 3Ô∏è‚É£ Estrutura das Tabelas (Exemplo Base)

#### Tabela Consolidada (Destino)

```
tbl_processado_operacao_consolidada
```

#### Tabelas Principais (Mesmo Schema)

* SoR (Online): `tbl_processado_operacao_sor`
* SoT (Batch): `tbl_processado_operacao_apropriada`

> Observa√ß√£o: As tr√™s possuem **schema id√™ntico**, mas respondem a **fontes de verdade diferentes**.

---

### 4Ô∏è‚É£ Campos-Chave da Regra de Decis√£o

A escolha entre SoR e SoT √© feita por **ranking** baseado nos seguintes campos:

* `dat_vlr_even_oper`
* `num_prio_even_oper`
* `dat_recm_even_oper`

Ordena√ß√£o:

```
dat_vlr_even_oper DESC
num_prio_even_oper DESC
dat_recm_even_oper DESC
```

---

### 5Ô∏è‚É£ Tabelas Auxiliares

Cada camada possui suas pr√≥prias auxiliares:

#### Auxiliares da SoR

* `tbl_operecao_sor`
* `tbl_evento_processado_sor`
* `tbl_posicao_operacao_sor`

#### Auxiliares da SoT

* `tbl_operecao_apropriada`
* `tbl_evento_processado_apropriada`
* `tbl_posicao_operacao_apropriada`

Essas tabelas s√£o utilizadas para **construir a base de compara√ß√£o**, a partir da qual ser√° feita a decis√£o entre SoR e SoT.

---

### 6Ô∏è‚É£ L√≥gica de Compara√ß√£o (Regra de Neg√≥cio)

#### Consulta Base ‚Äì SoR (Online)

```
select
    oper.num_oper,
    oper.cod_idef_ver_oper,
    posi.dat_vlr_even_oper,
    posi.num_prio_even_oper,
    posi.dat_recm_even_oper
from db_online.tbl_operecao_sor oper
inner join db_online.tbl_evento_processado_sor event
    on oper.num_oper = event.num_oper
   and oper.cod_idef_ver_oper = event.cod_idef_ver_oper
inner join db_online.tbl_posicao_operacao_sor posi
    on oper.num_oper = posi.num_oper
   and oper.cod_idef_even_prcs = posi.cod_idef_even_prcs
where anomesdia = '20260115'
```

#### Consulta Base ‚Äì SoT (Batch)

```
select
    oper.num_oper,
    oper.cod_idef_ver_oper,
    posi.dat_vlr_even_oper,
    posi.num_prio_even_oper,
    posi.dat_recm_even_oper
from db_online.tbl_operecao_apropriada oper
inner join db_online.tbl_evento_processado_apropriada event
    on oper.num_oper = event.num_oper
   and oper.cod_idef_ver_oper = event.cod_idef_ver_oper
inner join db_online.tbl_posicao_operacao_apropriada posi
    on oper.num_oper = posi.num_oper
   and oper.cod_idef_even_prcs = posi.cod_idef_even_prcs
where anomesdia = '20260115'
```

---

### 7Ô∏è‚É£ Uni√£o e Ranking (Regra Decis√≥ria)

Ap√≥s a constru√ß√£o das duas bases:

1. Unir SoR + SoT.
2. Aplicar `row_number()` particionado por:

   * `num_oper`
   * `cod_idef_ver_oper`
3. Ordenar pelos campos de decis√£o.

```
row_number() over (
    partition by num_oper, cod_idef_ver_oper
    order by dat_vlr_even_oper desc,
             num_prio_even_oper desc,
             dat_recm_even_oper desc
)
```

4. Selecionar apenas `rank = 1`.
5. O resultado determina:

   * Qual **origem venceu** (`online` ou `batch`).
   * Quais registros devem ser filtrados nas tabelas principais.

---

### 8Ô∏è‚É£ Constru√ß√£o da Tabela Consolidada

1. O resultado do ranking **define quais chaves (num_oper, cod_idef_ver_oper)** devem ser extra√≠das:

   * Da SoR (`tbl_processado_operacao_sor`)
   * Ou da SoT (`tbl_processado_operacao_apropriada`)
2. Esses registros s√£o ent√£o **gravados em**:

```
tbl_processado_operacao_consolidada
```

---

### 9Ô∏è‚É£ Configura√ß√£o Din√¢mica (Settings)

Todas as regras devem ser **100% orientadas por configura√ß√£o**, via estrutura como:

* Tabela consolidada
* Principais (SoR / SoT)
* Auxiliares (opcionais)
* Joins din√¢micos
* Chaves principais
* Campos de decis√£o

Exemplo: m√∫ltiplas tabelas consolidadas (10 no total), cada uma podendo:

* Ter ou n√£o auxiliares.
* Ter joins diferentes.
* Ter chaves diferentes.

Nenhuma tabela deve estar ‚Äúhardcoded‚Äù.

---

### üîü Arquitetura Obrigat√≥ria

A implementa√ß√£o deve:

* Usar uma classe de regra: `NovaRegraConsolidacao`, herdando de `BaseBusinessProcessor`.
* Expor o m√©todo:

```
processar(database: str, tabela_consolidada: str, execution_date: str)
```

* Ser executada pelo `main` atrav√©s de:

  * `ProcessorFactory`
  * `BusinessRuleOrchestrator`
  * `JourneyController`

* O `main` deve:

  * Iterar sobre **todas as tabelas consolidadas**.
  * Gerar **uma idempotency_key por tabela**.
  * **N√£o interromper o processamento das demais em caso de erro**.
  * Registrar m√©tricas e estado no DynamoDB.

---

### 1Ô∏è‚É£1Ô∏è‚É£ Restri√ß√µes T√©cnicas

* ‚ùå **N√£o usar `spark.sql`**
* ‚úÖ Usar apenas:

  * DataFrames
  * GlueContext
  * boto3 (Glue API)
* ‚úÖ Implementar m√©todo para:

  * Obter **√∫ltima parti√ß√£o** via Glue (`get_partitions`).
* ‚úÖ Implementar:

  * Leitura din√¢mica das tabelas
  * Joins configur√°veis
  * Ranking com `Window`
  * Escrita em S3 / Glue Catalog
  * Registro no DynamoDB

---

### 1Ô∏è‚É£2Ô∏è‚É£ Objetivo Final

Entregar uma solu√ß√£o que:

* Execute a mesma regra de neg√≥cio para **10 tabelas consolidadas diferentes**.
* Leia **sempre a √∫ltima parti√ß√£o** das tabelas SoR e SoT.
* Decida dinamicamente entre SoR e SoT por ranking.
* Seja:

  * Idempotente
  * Tolerante a falhas
  * Totalmente configur√°vel
  * Aderente √† arquitetura existente (ProcessorFactory, Orchestrator, JourneyController).

---

Se quiser, no pr√≥ximo passo posso:

* Transformar este prompt diretamente em:

  * **Classe `NovaRegraConsolidacao` completa**
  * **Adapta√ß√£o do seu `main` para executar as 10 consolida√ß√µes**
  * **Implementa√ß√£o correta de `get_latest_partition` no `GlueDataHandler` sem spark.sql**

Basta dizer:
**‚ÄúPode gerar a implementa√ß√£o a partir deste prompt.‚Äù**
