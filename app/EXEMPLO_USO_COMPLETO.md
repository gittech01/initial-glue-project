# Exemplo de Uso Completo - Sistema Agn√≥stico

## üéØ Cen√°rios de Uso

### **Cen√°rio 1: Processamento B√°sico de Dados**

```bash
# Executar job com data_processor
glue-job \
  --JOB_NAME process_data_job \
  --processor_type data_processor \
  --database vendas \
  --table_name faturamento \
  --output_path s3://bucket/processed/faturamento
```

**O que acontece:**

1. `main.py` recebe `processor_type=data_processor`
2. `ProcessorFactory.create()` cria `DataProcessor`
3. `BusinessRuleOrchestrator.execute_rule()` executa
4. `BaseBusinessProcessor.process()` (template method) roda:
   - L√™ dados do cat√°logo
   - Agrega dados
   - Salva congregado no DynamoDB
   - Escreve no S3

---

### **Cen√°rio 2: An√°lise de Vendas**

```bash
# Executar job com sales_analyzer
glue-job \
  --JOB_NAME analyze_sales_job \
  --processor_type sales_analyzer \
  --database vendas \
  --table_name vendas \
  --periodo 2024-01 \
  --output_path s3://bucket/analises/2024-01
```

**O que acontece:**

1. `main.py` recebe `processor_type=sales_analyzer`
2. `ProcessorFactory.create()` cria `SalesAnalyzer`
3. Mesmo fluxo, mas com l√≥gica espec√≠fica:
   - Filtra por per√≠odo
   - Calcula totais e m√©dias
   - Agrupa por categoria
   - Salva an√°lise no DynamoDB

---

### **Cen√°rio 3: M√∫ltiplas Regras em Paralelo**

```python
from utils.business import ProcessorFactory, BusinessRuleOrchestrator
from utils.config import AppConfig
from utils.handlers import GlueDataHandler
from utils import JourneyController, DynamoDBHandler

# Setup
config = AppConfig()
glue_handler = GlueDataHandler(glue_context)
journey_controller = JourneyController(...)
dynamodb_handler = DynamoDBHandler(...)

orchestrator = BusinessRuleOrchestrator(
    journey_controller=journey_controller,
    continue_on_error=True  # ‚Üê N√£o interrompe em caso de falha
)

# Criar m√∫ltiplos processadores
processor1 = ProcessorFactory.create('data_processor', ...)
processor2 = ProcessorFactory.create('sales_analyzer', ...)
processor3 = ProcessorFactory.create('inventory_processor', ...)

# Executar todos (isolados)
rules = [
    {
        'processor': processor1,
        'idempotency_key': 'data_2024-01',
        'database': 'vendas',
        'table_name': 'faturamento'
    },
    {
        'processor': processor2,
        'idempotency_key': 'sales_2024-01',
        'database': 'vendas',
        'table_name': 'vendas',
        'periodo': '2024-01'
    },
    {
        'processor': processor3,
        'idempotency_key': 'inventory_2024-01',
        'database': 'estoque',
        'table_name': 'produtos',
        'categoria': 'eletronicos'
    }
]

# Executar todos (falhas n√£o interrompem outras)
results = orchestrator.execute_multiple_rules(rules)

# Resultado:
# {
#   'total': 3,
#   'successful': 2,
#   'failed': 1,
#   'skipped': 0,
#   'results': {
#     'DataProcessor': {'status': 'SUCCESS', ...},
#     'SalesAnalyzer': {'status': 'SUCCESS', ...},
#     'InventoryProcessor': {'status': 'FAILED', 'error': '...'}
#   }
# }
```

**Benef√≠cio:** Se `InventoryProcessor` falhar, `DataProcessor` e `SalesAnalyzer` continuam executando.

---

### **Cen√°rio 4: Adicionar Nova Regra (Sem Modificar C√≥digo)**

#### **Passo 1: Criar Classe**

```python
# utils/business/customer_processor.py
from utils.business.base_processor import BaseBusinessProcessor

class CustomerProcessor(BaseBusinessProcessor):
    def _read_data(self, **kwargs):
        return self.glue_handler.read_from_catalog(
            database=kwargs['database'],
            table_name=kwargs['table_name']
        )

    def _transform_data(self, df, **kwargs):
        # L√≥gica espec√≠fica de clientes
        return {
            'total_customers': df.count(),
            'active_customers': df.filter(F.col('status') == 'active').count(),
            ...
        }

    def _get_congregado_key(self, **kwargs):
        return f"customers_{kwargs['database']}_{kwargs['table_name']}"
```

#### **Passo 2: Registrar**

```python
# Em processor_factory.py ou no __init__.py
from utils.business.customer_processor import CustomerProcessor
ProcessorFactory.register('customer_processor', CustomerProcessor)
```

#### **Passo 3: Usar (Sem Modificar main.py!)**

```bash
glue-job \
  --processor_type customer_processor \
  --database clientes \
  --table_name clientes \
  --output_path s3://bucket/customers
```

**Pronto!** Sistema funciona sem modificar c√≥digo existente.

---

## üîÑ Fluxo Resiliente (N√£o Interrompe)

### **Exemplo: M√∫ltiplas Execu√ß√µes com Falhas**

```python
orchestrator = BusinessRuleOrchestrator(
    continue_on_error=True,  # ‚Üê Chave para n√£o interromper
    max_concurrent_failures=3
)

# Executar 5 regras
results = orchestrator.execute_multiple_rules([
    {'processor': p1, 'idempotency_key': 'key1', ...},  # ‚úÖ Sucesso
    {'processor': p2, 'idempotency_key': 'key2', ...},  # ‚ùå Falha
    {'processor': p3, 'idempotency_key': 'key3', ...},  # ‚úÖ Sucesso
    {'processor': p4, 'idempotency_key': 'key4', ...},  # ‚ùå Falha
    {'processor': p5, 'idempotency_key': 'key5', ...},  # ‚úÖ Sucesso
])

# Resultado:
# {
#   'total': 5,
#   'successful': 3,  # ‚Üê 3 executaram com sucesso
#   'failed': 2,       # ‚Üê 2 falharam mas n√£o interromperam
#   'results': {
#     'Processor1': {'status': 'SUCCESS', ...},
#     'Processor2': {'status': 'FAILED', 'error': '...'},  # ‚Üê Falhou mas n√£o parou
#     'Processor3': {'status': 'SUCCESS', ...},
#     'Processor4': {'status': 'FAILED', 'error': '...'},  # ‚Üê Falhou mas n√£o parou
#     'Processor5': {'status': 'SUCCESS', ...}
#   }
# }
```

**Benef√≠cio:** Sistema continua funcionando mesmo com falhas parciais.

---

## üìä Compara√ß√£o: Antes vs Depois

### **Antes (Acoplado):**

```python
# main.py
if args['tipo'] == 'data':
    processor = DataProcessor(...)
elif args['tipo'] == 'sales':
    processor = SalesAnalyzer(...)
else:
    raise ValueError("Tipo desconhecido")

# ‚ùå Problemas:
# - Precisa modificar main.py para cada nova regra
# - C√≥digo acoplado
# - Dif√≠cil testar
```

### **Depois (Agn√≥stico):**

```python
# main.py
processor = ProcessorFactory.create(
    processor_type=args.get('processor_type'),
    ...
)

# ‚úÖ Benef√≠cios:
# - N√£o precisa modificar main.py
# - C√≥digo desacoplado
# - F√°cil testar
# - F√°cil adicionar novas regras
```

---

## üéØ Design Patterns em A√ß√£o

### **1. Factory Pattern**

```python
# Cria sem conhecer classe concreta
processor = ProcessorFactory.create('sales_analyzer', ...)
# ‚Üë N√£o sabe que √© SalesAnalyzer, apenas o tipo
```

### **2. Template Method**

```python
# Todas as regras seguem mesmo template
class MinhaRegra(BaseBusinessProcessor):
    def _read_data(...):      # Hook
    def _transform_data(...): # Hook
    # process() j√° est√° implementado na base
```

### **3. Strategy Pattern**

```python
# Diferentes estrat√©gias intercambi√°veis
strategies = [
    ProcessorFactory.create('data_processor', ...),
    ProcessorFactory.create('sales_analyzer', ...),
    ProcessorFactory.create('inventory_processor', ...)
]
# Todas implementam mesma interface
```

### **4. Orchestrator Pattern**

```python
# Coordena m√∫ltiplas execu√ß√µes
orchestrator.execute_multiple_rules(rules)
# Gerencia isolamento e resili√™ncia
```

---

## ‚úÖ Checklist de Uso

- [x] Sistema agn√≥stico para m√∫ltiplas regras
- [x] Factory Pattern para cria√ß√£o
- [x] Template Method para consist√™ncia
- [x] Orchestrator para resili√™ncia
- [x] Fluxo n√£o interrompe em caso de falha
- [x] SalesAnalyzer implementado
- [x] Exemplo de nova regra (InventoryProcessor)
- [x] Documenta√ß√£o completa

---

**üéâ Sistema pronto para produ√ß√£o com design patterns e arquitetura agn√≥stica!**
